{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Heidelberg Tutorial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial we will be learning how to use NeuroTorch to train a neural network to recognize audio recordings of spoken digits."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can install the dependencies by running the following commands:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JeremieGince/PythonBasicTools (from -r heidelberg_requirements.txt (line 15))\n",
      "  Cloning https://github.com/JeremieGince/PythonBasicTools to c:\\users\\gince\\appdata\\local\\temp\\pip-req-build-w2nbkj8c\n",
      "  Resolved https://github.com/JeremieGince/PythonBasicTools to commit 63b55f13565762b20503a55c3abf4105e0f28064\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting matplotlib>=3.5.2\n",
      "  Using cached matplotlib-3.6.0-cp39-cp39-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: numpy>=1.22.3 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 2)) (1.23.3)\n",
      "Requirement already satisfied: setuptools>=57.0.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 3)) (60.2.0)\n",
      "Requirement already satisfied: torch>=1.12.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 4)) (1.12.1+cu116)\n",
      "Requirement already satisfied: torchvision>=0.13.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 5)) (0.13.1+cu116)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 6)) (4.64.1)\n",
      "Requirement already satisfied: h5py>=3.7.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 7)) (3.7.0)\n",
      "Requirement already satisfied: six>=1.16.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: psutil>=5.9.1 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 10)) (5.9.2)\n",
      "Collecting pandas>=1.4.3\n",
      "  Using cached pandas-1.5.0-cp39-cp39-win_amd64.whl (10.9 MB)\n",
      "Collecting scikit-learn>=1.1.1\n",
      "  Using cached scikit_learn-1.1.2-cp39-cp39-win_amd64.whl (7.4 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.37.3-py3-none-any.whl (959 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from matplotlib>=3.5.2->-r heidelberg_requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from matplotlib>=3.5.2->-r heidelberg_requirements.txt (line 1)) (2.8.2)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.5-cp39-cp39-win_amd64.whl (161 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from matplotlib>=3.5.2->-r heidelberg_requirements.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from matplotlib>=3.5.2->-r heidelberg_requirements.txt (line 1)) (9.2.0)\n",
      "Requirement already satisfied: typing-extensions in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from torch>=1.12.0->-r heidelberg_requirements.txt (line 4)) (4.3.0)\n",
      "Requirement already satisfied: requests in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from torchvision>=0.13.0->-r heidelberg_requirements.txt (line 5)) (2.28.1)\n",
      "Requirement already satisfied: colorama in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from tqdm>=4.64.0->-r heidelberg_requirements.txt (line 6)) (0.4.5)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.2.1-py2.py3-none-any.whl (500 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.9.1-cp39-cp39-win_amd64.whl (38.6 MB)\n",
      "Requirement already satisfied: pytest>=7.1.2 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from PythonBasicTools==0.0.0.1->-r heidelberg_requirements.txt (line 15)) (7.1.3)\n",
      "Requirement already satisfied: docutils>=0.17.1 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from PythonBasicTools==0.0.0.1->-r heidelberg_requirements.txt (line 15)) (0.19)\n",
      "Requirement already satisfied: tomli>=1.0.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from pytest>=7.1.2->PythonBasicTools==0.0.0.1->-r heidelberg_requirements.txt (line 15)) (2.0.1)\n",
      "Requirement already satisfied: iniconfig in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from pytest>=7.1.2->PythonBasicTools==0.0.0.1->-r heidelberg_requirements.txt (line 15)) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from pytest>=7.1.2->PythonBasicTools==0.0.0.1->-r heidelberg_requirements.txt (line 15)) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from pytest>=7.1.2->PythonBasicTools==0.0.0.1->-r heidelberg_requirements.txt (line 15)) (1.11.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from pytest>=7.1.2->PythonBasicTools==0.0.0.1->-r heidelberg_requirements.txt (line 15)) (22.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from requests->torchvision>=0.13.0->-r heidelberg_requirements.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from requests->torchvision>=0.13.0->-r heidelberg_requirements.txt (line 5)) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from requests->torchvision>=0.13.0->-r heidelberg_requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from requests->torchvision>=0.13.0->-r heidelberg_requirements.txt (line 5)) (1.26.12)\n",
      "Installing collected packages: threadpoolctl, scipy, pytz, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, pandas, matplotlib\n",
      "Successfully installed contourpy-1.0.5 cycler-0.11.0 fonttools-4.37.3 joblib-1.2.0 kiwisolver-1.4.4 matplotlib-3.6.0 pandas-1.5.0 pytz-2022.2.1 scikit-learn-1.1.2 scipy-1.9.1 threadpoolctl-3.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none -q https://github.com/JeremieGince/PythonBasicTools 'C:\\Users\\gince\\AppData\\Local\\Temp\\pip-req-build-w2nbkj8c'\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'E:\\Github\\NeuroTorch\\tutorials\\heidelberg\\heidelberg_venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JeremieGince/PythonBasicTools"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none -q https://github.com/JeremieGince/PythonBasicTools 'C:\\Users\\gince\\AppData\\Local\\Temp\\pip-req-build-kt7nlojz'\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'E:\\Github\\NeuroTorch\\tutorials\\heidelberg\\heidelberg_venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cloning https://github.com/JeremieGince/PythonBasicTools to c:\\users\\gince\\appdata\\local\\temp\\pip-req-build-kt7nlojz\n",
      "  Resolved https://github.com/JeremieGince/PythonBasicTools to commit 63b55f13565762b20503a55c3abf4105e0f28064\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.62.3 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from PythonBasicTools==0.0.0.1) (4.64.1)\n",
      "Requirement already satisfied: docutils>=0.17.1 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from PythonBasicTools==0.0.0.1) (0.19)\n",
      "Requirement already satisfied: setuptools>=57.0.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from PythonBasicTools==0.0.0.1) (60.2.0)\n",
      "Requirement already satisfied: psutil>=5.9.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from PythonBasicTools==0.0.0.1) (5.9.2)\n",
      "Requirement already satisfied: pytest>=7.1.2 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from PythonBasicTools==0.0.0.1) (7.1.3)\n",
      "Requirement already satisfied: colorama in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from pytest>=7.1.2->PythonBasicTools==0.0.0.1) (0.4.5)\n",
      "Requirement already satisfied: tomli>=1.0.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from pytest>=7.1.2->PythonBasicTools==0.0.0.1) (2.0.1)\n",
      "Requirement already satisfied: iniconfig in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from pytest>=7.1.2->PythonBasicTools==0.0.0.1) (1.1.1)\n",
      "Requirement already satisfied: packaging in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from pytest>=7.1.2->PythonBasicTools==0.0.0.1) (21.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from pytest>=7.1.2->PythonBasicTools==0.0.0.1) (22.1.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from pytest>=7.1.2->PythonBasicTools==0.0.0.1) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from pytest>=7.1.2->PythonBasicTools==0.0.0.1) (1.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in e:\\github\\neurotorch\\tutorials\\heidelberg\\heidelberg_venv\\lib\\site-packages (from packaging->pytest>=7.1.2->PythonBasicTools==0.0.0.1) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r heidelberg_requirements.txt\n",
    "!pip install git+https://github.com/JeremieGince/PythonBasicTools"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/JeremieGince/NeuroTorch.git"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you have a cuda device and want to use it for this tutorial (it is recommended to do so), you can uninstall pytorch with `pip uninstall torch` and re-install it with the right cuda version by generating a command with [PyTorch GetStarted](https://pytorch.org/get-started/locally/) web page."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After setting up the virtual environment, we will need to import the necessary packages."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from pythonbasictools.device import log_device_setup, DeepLib\n",
    "from pythonbasictools.logging import logs_file_setup\n",
    "\n",
    "from dataset import get_dataloaders\n",
    "import neurotorch as nt\n",
    "from neurotorch import Dimension, DimensionProperty\n",
    "from neurotorch.modules import HeavisideSigmoidApprox\n",
    "from neurotorch.callbacks import CheckpointManager, LoadCheckpointMode\n",
    "from neurotorch.metrics import ClassificationMetrics\n",
    "from neurotorch.modules import SequentialModel\n",
    "from neurotorch.modules.layers import SpyLIFLayer, SpyLILayer\n",
    "from neurotorch.trainers import ClassificationTrainer\n",
    "from neurotorch.regularization import RegularizationList, L2, L1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Logs file at: .//logs/logs-20-09-2022/heidelberg_tutorial-16637289759816937.log\n",
      "\n",
      "INFO:root:__Python VERSION: 3.9.12 (tags/v3.9.12:b28265d, Mar 23 2022, 23:52:46) [MSC v.1929 64 bit (AMD64)]\n",
      "INFO:root:Number of available cores: 12.\n",
      "INFO:root:Number of available logical processors: 24.\n",
      "INFO:root:__pyTorch VERSION:1.12.1+cu116\n",
      "INFO:root:__CUDA VERSION:\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\r\n",
      "Built on Mon_Nov_30_19:15:10_Pacific_Standard_Time_2020\r\n",
      "Cuda compilation tools, release 11.2, V11.2.67\r\n",
      "Build cuda_11.2.r11.2/compiler.29373293_0\r\n",
      "\n",
      "INFO:root:__nvidia-smi: Not Found\n",
      "INFO:root:__CUDNN VERSION:8302\n",
      "INFO:root:__Number CUDA Devices:1\n",
      "INFO:root:\n",
      "-------------------------\n",
      "DEVICE: cuda\n",
      "-------------------------\n",
      "\n",
      "INFO:root:NVIDIA GeForce RTX 3070\n",
      "INFO:root:Memory Usage:\n",
      "INFO:root:Allocated: 0.0 GB\n",
      "INFO:root:Cached:   0.0 GB\n",
      "INFO:root:Memory summary: \n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_file_setup(\"heidelberg_tutorial\", add_stdout=False)\n",
    "log_device_setup(deepLib=DeepLib.Pytorch)\n",
    "if torch.cuda.is_available():\n",
    "\ttorch.cuda.set_per_process_memory_fraction(0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's the time to defined our training and networks parameters. In the following,\n",
    "\n",
    "- the number of iteration is the number of time the trainer will pass through the entire training dataset;\n",
    "- the batch size is the number of samples that will be loaded at the same time for each forward and backward pass;\n",
    "- the learning rate is the learning rate used by the optimizer;\n",
    "- the random seed is the seed used by the random number generator;\n",
    "- the number of steps is the number of euler integration steps performed by the model during each forward and backward pass;\n",
    "- the number of hidden neurons is the number of neurons that will be used in the hidden layer of the model;\n",
    "- dt is the time step of the euler integration;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_iterations = 50\n",
    "batch_size = 256\n",
    "learning_rate = 2e-4\n",
    "seed = 42\n",
    "\n",
    "# Network parameters\n",
    "dynamic_type = nt.SpyLIFLayer\n",
    "n_steps = 100\n",
    "n_hidden_neurons = 256\n",
    "dt = 1e-3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x2d03e5b9310>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we're initializing a callback of the trainer used to save the network during the training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "checkpoint_folder = f\"./checkpoints/heidelberg_{dynamic_type.__name__}\"\n",
    "checkpoint_manager = CheckpointManager(checkpoint_folder, metric=\"val_accuracy\", minimise_metric=False, save_best_only=True, start_save_at=int(n_iterations * 0.9))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Here is an exemple of the Heidelberg dataset:\n",
    "![Heidelberg_exemples](images/heidelberg_exemples.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dataloaders = get_dataloaders(\n",
    "\tbatch_size=batch_size,\n",
    "\ttrain_val_split_ratio=0.95,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can finally define our model. The sequential model is a neural network that is composed of a list of layers. The list of layers is ordered and the first layer is the input layer. The last layer is the output layer. The sequential model can be found in the subpackage `neurotorch.modules`. Note that we can specify the input transform that will be applied to the input data before the forward pass through the list of layers. If the transformation is computationally expensive, it is recommended to put it in the dataloaders instead of the model for the training. Usually the input transform in the model is used when the model is used for inference."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "network = SequentialModel(\n",
    "\tlayers=[\n",
    "\t\tdynamic_type(\n",
    "\t\t\tinput_size=nt.Size([\n",
    "\t\t\t\tDimension(None, DimensionProperty.TIME),\n",
    "\t\t\t\tDimension(dataloaders[\"test\"].dataset.n_units, DimensionProperty.NONE)\n",
    "\t\t\t]),\n",
    "\t\t\toutput_size=n_hidden_neurons,\n",
    "\t\t\tuse_recurrent_connection=True,\n",
    "\t\t\tspike_func=HeavisideSigmoidApprox,\n",
    "\t\t\tdt=dt,\n",
    "\t\t\t# spikes_regularization_factor=1e-6,\n",
    "\t\t),\n",
    "\t\tSpyLILayer(dt=dt, output_size=dataloaders[\"test\"].dataset.n_classes),\n",
    "\t],\n",
    "\tname=f\"heidelberg_network\",\n",
    "\tcheckpoint_folder=checkpoint_folder,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After the instantiation of the model, we have to build it, so it can infer the missing sizes of the layers in the model and create the tensors that will be used during the training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequentialModel(\n",
      "  (_to_device_transform): ToDevice(cuda, async=True)\n",
      "  (input_layers): ModuleDict(\n",
      "    (input_0): SpyLIFLayer<input_0>(700<->256)[LearningType.BPTT]@cuda\n",
      "  )\n",
      "  (hidden_layers): ModuleList()\n",
      "  (output_layers): ModuleDict(\n",
      "    (output_0): SpyLILayer<output_0>(256->20)[LearningType.BPTT]@cuda\n",
      "  )\n",
      "  (input_transform): ModuleDict(\n",
      "    (input_0): Sequential(\n",
      "      (0): CallableToModuleWrapper(Compose(\n",
      "          ToTensor()\n",
      "      ))\n",
      "      (1): ToDevice(cuda, async=True)\n",
      "    )\n",
      "  )\n",
      "  (output_transform): ModuleDict(\n",
      "    (output_0): IdentityTransform()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network.build()\n",
    "print(network)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "regularization = RegularizationList([\n",
    "\tL2(network.parameters(), Lambda=1e-5),\n",
    "\tL1(network.parameters(), Lambda=1e-6),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the next cell, we create the trainer that will be used to trained our network. They are several types of trainers that can be found in the subpackage `neurotorch.trainers` like the `ClassificationTrainer`, the `RegressionTrainer` or the `PPOTrainer`. In this tutorial, we will use the `ClassificationTrainer` because we are trying to classify some images. Note that the callbacks are some object that will be called during the training. They are found in the subpackage `neurotorch.callbacks` like the `CheckpointManager`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "trainer = ClassificationTrainer(\n",
    "\tmodel=network,\n",
    "\t# regularization=regularization,\n",
    "\toptimizer=torch.optim.Adam(network.parameters(), lr=learning_rate, weight_decay=0.0),\n",
    "\t# regularization_optimizer=torch.optim.SGD(regularization.parameters(), lr=1e-2, weight_decay=0.0),\n",
    "\tcallbacks=checkpoint_manager,\n",
    "\tverbose=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The training will start! Let's see how our simple network will perform on this task.\n",
    "\n",
    "Note: the argument `force_overwrite` is used to overwrite the existing checkpoint if it exists and the argument `load_checkpoint_mode` if the model will be loaded from the last checkpoint (`LoadCheckpointMode.LAST_ITR`) or from the best checkpoint (`LoadCheckpointMode.BEST_ITR`). The loading mode is really useful when you want to stop the training and restart it later."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/50 [00:00<?, ?itr/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a24022c9c244b16935c49ed91f0cd97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_history = trainer.train(\n",
    "\tdataloaders[\"train\"],\n",
    "\tdataloaders[\"val\"],\n",
    "\tn_iterations=n_iterations,\n",
    "\tload_checkpoint_mode=LoadCheckpointMode.LAST_ITR,\n",
    "\t# force_overwrite=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The training is finished! Let's see how our network learned over the iterations.\n",
    "\n",
    "Note: the next graphs are really useful to see if the model overfit or underfit the data over the iterations. It's why you can use the callback `TrainingHistoryVisualizationCallback` to see those graphs in real time."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_history.plot(show=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can load the model at the best or the last iteration for the testing phase."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network.load_checkpoint(checkpoint_manager.checkpoints_meta_path, LoadCheckpointMode.BEST_ITR, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now see how our network perform on the test dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = {\n",
    "\tk: ClassificationMetrics.compute_y_true_y_pred(network, dataloader, verbose=True, desc=f\"{k} predictions\")\n",
    "\tfor k, dataloader in dataloaders.items()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracies = {\n",
    "\tk: ClassificationMetrics.accuracy(network, y_true=y_true, y_pred=y_pred)\n",
    "\tfor k, (y_true, y_pred) in predictions.items()\n",
    "}\n",
    "pprint.pprint(accuracies)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see the results on other popular classification metrics."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precisions = {\n",
    "\tk: ClassificationMetrics.precision(network, y_true=y_true, y_pred=y_pred)\n",
    "\tfor k, (y_true, y_pred) in predictions.items()\n",
    "}\n",
    "recalls = {\n",
    "\tk: ClassificationMetrics.recall(network, y_true=y_true, y_pred=y_pred)\n",
    "\tfor k, (y_true, y_pred) in predictions.items()\n",
    "}\n",
    "f1s = {\n",
    "\tk: ClassificationMetrics.f1(network, y_true=y_true, y_pred=y_pred)\n",
    "\tfor k, (y_true, y_pred) in predictions.items()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = OrderedDict(dict(\n",
    "\tnetwork=network,\n",
    "\taccuracies=accuracies,\n",
    "\tprecisions=precisions,\n",
    "\trecalls=recalls,\n",
    "\tf1s=f1s,\n",
    "))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pprint.pprint(results, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the end of the tutorial!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "NeuroTorch is a library that allows you to easily build neural networks and train them. Moreover, it allows you to do audio signal classification using dynamics from neurosciences."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}