{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Heidelberg Tutorial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can install the dependencies by running the following commands:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JeremieGince/PythonBasicTools (from -r heidelberg_requirements.txt (line 13))\n",
      "  Cloning https://github.com/JeremieGince/PythonBasicTools to c:\\users\\gince\\appdata\\local\\temp\\pip-req-build-8juls0ma\n",
      "  Resolved https://github.com/JeremieGince/PythonBasicTools to commit f07c2041a00667b870e1c99bb42e96d537c4a05c\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib==3.5.2 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 1)) (3.5.2)\n",
      "Requirement already satisfied: numpy~=1.22.3 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 2)) (1.22.4)\n",
      "Requirement already satisfied: setuptools~=57.0.0 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 3)) (57.0.0)\n",
      "Requirement already satisfied: torch~=1.12.0 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 4)) (1.12.0+cu113)\n",
      "Requirement already satisfied: torchvision~=0.13.0 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 5)) (0.13.0)\n",
      "Requirement already satisfied: tqdm==4.64.0 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 6)) (4.64.0)\n",
      "Requirement already satisfied: h5py~=3.7.0 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 7)) (3.7.0)\n",
      "Requirement already satisfied: six~=1.16.0 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: psutil>=5.9.1 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 10)) (5.9.1)\n",
      "Requirement already satisfied: pandas>=1.4.3 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 11)) (1.4.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.1 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from -r heidelberg_requirements.txt (line 12)) (1.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from matplotlib==3.5.2->-r heidelberg_requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from matplotlib==3.5.2->-r heidelberg_requirements.txt (line 1)) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from matplotlib==3.5.2->-r heidelberg_requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from matplotlib==3.5.2->-r heidelberg_requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from matplotlib==3.5.2->-r heidelberg_requirements.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from matplotlib==3.5.2->-r heidelberg_requirements.txt (line 1)) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from matplotlib==3.5.2->-r heidelberg_requirements.txt (line 1)) (4.34.4)\n",
      "Requirement already satisfied: colorama in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from tqdm==4.64.0->-r heidelberg_requirements.txt (line 6)) (0.4.5)\n",
      "Requirement already satisfied: typing-extensions in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from torch~=1.12.0->-r heidelberg_requirements.txt (line 4)) (4.3.0)\n",
      "Requirement already satisfied: requests in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from torchvision~=0.13.0->-r heidelberg_requirements.txt (line 5)) (2.28.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from pandas>=1.4.3->-r heidelberg_requirements.txt (line 11)) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from scikit-learn>=1.1.1->-r heidelberg_requirements.txt (line 12)) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from scikit-learn>=1.1.1->-r heidelberg_requirements.txt (line 12)) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from scikit-learn>=1.1.1->-r heidelberg_requirements.txt (line 12)) (1.8.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from requests->torchvision~=0.13.0->-r heidelberg_requirements.txt (line 5)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from requests->torchvision~=0.13.0->-r heidelberg_requirements.txt (line 5)) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from requests->torchvision~=0.13.0->-r heidelberg_requirements.txt (line 5)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\github\\neurotorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages (from requests->torchvision~=0.13.0->-r heidelberg_requirements.txt (line 5)) (1.26.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none -q https://github.com/JeremieGince/PythonBasicTools 'C:\\Users\\gince\\AppData\\Local\\Temp\\pip-req-build-8juls0ma'\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.2 is available.\n",
      "You should consider upgrading via the 'E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JeremieGince/NeuroTorch.git\n",
      "  Cloning https://github.com/JeremieGince/NeuroTorch.git to c:\\users\\gince\\appdata\\local\\temp\\pip-req-build-6y8hgsvy\n",
      "  Resolved https://github.com/JeremieGince/NeuroTorch.git to commit 8e73cf099e79165ff800982684d3df35188eb229\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none -q https://github.com/JeremieGince/NeuroTorch.git 'C:\\Users\\gince\\AppData\\Local\\Temp\\pip-req-build-6y8hgsvy'\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\Scripts\\python.exe' 'E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\gince\\AppData\\Local\\Temp\\tmp5cvcxo6e'\n",
      "       cwd: C:\\Users\\gince\\AppData\\Local\\Temp\\pip-req-build-6y8hgsvy\n",
      "  Complete output (23 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 363, in <module>\n",
      "      main()\n",
      "    File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 345, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 130, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "    File \"C:\\Users\\gince\\AppData\\Local\\Temp\\pip-build-env-ndmk6zwn\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 177, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(\n",
      "    File \"C:\\Users\\gince\\AppData\\Local\\Temp\\pip-build-env-ndmk6zwn\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 159, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\gince\\AppData\\Local\\Temp\\pip-build-env-ndmk6zwn\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 281, in run_setup\n",
      "      super(_BuildMetaLegacyBackend,\n",
      "    File \"C:\\Users\\gince\\AppData\\Local\\Temp\\pip-build-env-ndmk6zwn\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 174, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"C:\\Users\\gince\\AppData\\Local\\Temp\\pip-req-build-6y8hgsvy\\src\\neurotorch\\__init__.py\", line 12, in <module>\n",
      "      from .modules.layers import (\n",
      "    File \"C:\\Users\\gince\\AppData\\Local\\Temp\\pip-req-build-6y8hgsvy\\src\\neurotorch\\modules\\__init__.py\", line 2, in <module>\n",
      "      from .spike_funcs import (\n",
      "    File \"C:\\Users\\gince\\AppData\\Local\\Temp\\pip-req-build-6y8hgsvy\\src\\neurotorch\\modules\\spike_funcs.py\", line 3, in <module>\n",
      "      import torch\n",
      "  ModuleNotFoundError: No module named 'torch'\n",
      "  ----------------------------------------\n",
      "WARNING: Discarding git+https://github.com/JeremieGince/NeuroTorch.git. Command errored out with exit status 1: 'E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\Scripts\\python.exe' 'E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\gince\\AppData\\Local\\Temp\\tmp5cvcxo6e' Check the logs for full command output.\n",
      "ERROR: Command errored out with exit status 1: 'E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\Scripts\\python.exe' 'E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\gince\\AppData\\Local\\Temp\\tmp5cvcxo6e' Check the logs for full command output.\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.2 is available.\n",
      "You should consider upgrading via the 'E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r heidelberg_requirements.txt\n",
    "!pip install git+https://github.com/JeremieGince/NeuroTorch.git"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you have a cuda device and want to use it for this tutorial (it is recommended to do so), you can uninstall pytorch with `pip uninstall torch` and re-install it with the right cuda version by generating a command with [PyTorch GetStarted](https://pytorch.org/get-started/locally/) web page."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After setting up the virtual environment, we will need to import the necessary packages."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from pythonbasictools.device import log_device_setup, DeepLib\n",
    "from pythonbasictools.logging import logs_file_setup\n",
    "\n",
    "from applications.heidelberg.dataset import get_dataloaders\n",
    "import neurotorch as nt\n",
    "from neurotorch import Dimension, DimensionProperty\n",
    "from neurotorch.modules import HeavisideSigmoidApprox\n",
    "from neurotorch.callbacks import CheckpointManager, LoadCheckpointMode\n",
    "from neurotorch.metrics import ClassificationMetrics\n",
    "from neurotorch.modules import SequentialModel\n",
    "from neurotorch.modules.layers import SpyLIFLayer, SpyLILayer\n",
    "from neurotorch.trainers import ClassificationTrainer\n",
    "from neurotorch.regularization import RegularizationList, L2, L1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Logs file at: .//logs/logs-30-07-2022/heidelberg_tutoriel-16592353440478294.log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs file at: .//logs/logs-30-07-2022/heidelberg_tutoriel-16592353440478294.log\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:__Python VERSION: 3.9.12 (tags/v3.9.12:b28265d, Mar 23 2022, 23:52:46) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.9.12 (tags/v3.9.12:b28265d, Mar 23 2022, 23:52:46) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Number of available cores: 12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available cores: 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Number of available logical processors: 24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available logical processors: 24.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:__pyTorch VERSION:1.12.0+cu113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__pyTorch VERSION:1.12.0+cu113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:__CUDA VERSION:\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\r\n",
      "Built on Mon_Nov_30_19:15:10_Pacific_Standard_Time_2020\r\n",
      "Cuda compilation tools, release 11.2, V11.2.67\r\n",
      "Build cuda_11.2.r11.2/compiler.29373293_0\r\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDA VERSION:\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\r\n",
      "Built on Mon_Nov_30_19:15:10_Pacific_Standard_Time_2020\r\n",
      "Cuda compilation tools, release 11.2, V11.2.67\r\n",
      "Build cuda_11.2.r11.2/compiler.29373293_0\r\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:__nvidia-smi: Not Found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__nvidia-smi: Not Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:__CUDNN VERSION:8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDNN VERSION:8302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:__Number CUDA Devices:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Number CUDA Devices:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "-------------------------\n",
      "DEVICE: cuda\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------\n",
      "DEVICE: cuda\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:NVIDIA GeForce RTX 3070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Memory Usage:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Allocated: 0.0 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Cached:   0.0 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached:   0.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Memory summary: \n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory summary: \n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_file_setup(\"heidelberg_tutoriel\")\n",
    "log_device_setup(deepLib=DeepLib.Pytorch)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.cuda.set_per_process_memory_fraction(0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "checkpoint_folder = f\"./checkpoints\"\n",
    "os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "checkpoint_manager = CheckpointManager(checkpoint_folder, metric=\"val_accuracy\", minimise_metric=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's the time to defined our training and networks parameters. In the following,\n",
    "\n",
    "- the number of iteration is the number of time the trainer will pass through the entire training dataset;\n",
    "- the batch size is the number of samples that will be loaded at the same time for each forward and backward pass;\n",
    "- the learning rate is the learning rate used by the optimizer;\n",
    "- the random seed is the seed used by the random number generator;\n",
    "- the number of steps is the number of euler integration steps performed by the model during each forward and backward pass;\n",
    "- the number of hidden neurons is the number of neurons that will be used in the hidden layer of the model;\n",
    "- dt is the time step of the euler integration;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_iterations = 100\n",
    "batch_size = 256  # Increase this if you have a GPU with more memory and decrease it otherwise.\n",
    "learning_rate = 2e-4\n",
    "seed = 42\n",
    "\n",
    "# Network parameters\n",
    "n_steps = 100\n",
    "n_hidden_neurons = 256\n",
    "dt = 1e-3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x18f25306e70>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Here is an exemple of the MNIST dataset:\n",
    "![Heidelberg_exemples](images/heidelberg_exemples.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dataloaders = get_dataloaders(\n",
    "\tbatch_size=batch_size,\n",
    "\ttrain_val_split_ratio=0.95,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can finally define our model. The sequential model is a neural network that is composed of a list of layers. The list of layers is ordered and the first layer is the input layer. The last layer is the output layer. The sequential model can be found in the subpackage `neurotorch.modules`. Note that we can specify the input transform that will be applied to the input data before the forward pass through the list of layers. If the transformation is computationally expensive, it is recommended to put it in the dataloaders instead of the model for the training. Usually the input transform in the model is used when the model is used for inference."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "network = SequentialModel(\n",
    "\tlayers=[\n",
    "\t\tSpyLIFLayer(\n",
    "\t\t\tinput_size=nt.Size([\n",
    "\t\t\t\tDimension(None, DimensionProperty.TIME),\n",
    "\t\t\t\tDimension(dataloaders[\"test\"].dataset.n_units, DimensionProperty.NONE)\n",
    "\t\t\t]),\n",
    "\t\t\toutput_size=n_hidden_neurons,\n",
    "\t\t\tuse_recurrent_connection=True,\n",
    "\t\t\tspike_func=HeavisideSigmoidApprox,\n",
    "\t\t\tdt=dt,\n",
    "\t\t),\n",
    "\t\tSpyLILayer(dt=dt, output_size=dataloaders[\"test\"].dataset.n_classes),\n",
    "\t],\n",
    "\tname=f\"heidelberg_network\",\n",
    "\tcheckpoint_folder=checkpoint_folder,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After the instantiation of the model, we have to build it, so it can infer the missing sizes of the layers in the model and create the tensors that will be used during the training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequentialModel(\n",
      "  (input_layers): ModuleDict(\n",
      "    (input_0): SpyLIFLayer<input_0>(700->256)[LearningType.BPTT]\n",
      "  )\n",
      "  (hidden_layers): ModuleList()\n",
      "  (output_layers): ModuleDict(\n",
      "    (output_0): SpyLILayer<output_0>(256->20)[LearningType.BPTT]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network.build()\n",
    "print(network)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "regularization = RegularizationList([\n",
    "\tL2(network.parameters()),\n",
    "\tL1(network.parameters()),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the next cell, we create the trainer that will be used to trained our network. They are several types of trainers that can be found in the subpackage `neurotorch.trainers` like the `ClassificationTrainer`, the `RegressionTrainer` or the `PPOTrainer`. In this tutorial, we will use the `ClassificationTrainer` because we are trying to classify some images. Note that the callbacks are some object that will be called during the training. They are found in the subpackage `neurotorch.callbacks` like the `CheckpointManager`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "trainer = ClassificationTrainer(\n",
    "\tmodel=network,\n",
    "\tregularization=regularization,\n",
    "\toptimizer=torch.optim.Adam(network.parameters(), lr=learning_rate, weight_decay=0.0),\n",
    "\tregularization_optimizer=torch.optim.Adam(regularization.parameters(), lr=learning_rate, weight_decay=0.0),\n",
    "\tcallbacks=checkpoint_manager,\n",
    "\tverbose=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The training will start! Let's see how our simple network will perform on this task.\n",
    "\n",
    "Note: the argument `force_overwrite` is used to overwrite the existing checkpoint if it exists and the argument `load_checkpoint_mode` if the model will be loaded from the last checkpoint (`LoadCheckpointMode.LAST_ITR`) or from the best checkpoint (`LoadCheckpointMode.BEST_ITR`). The loading mode is really useful when you want to stop the training and restart it later."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/100 [00:00<?, ?itr/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2161b2018f24e73983d3adba28138cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\torch\\autograd\\__init__.py:173: UserWarning: Error detected in AbsBackward0. Traceback of forward call that caused the error:\n",
      "  File \"C:\\Users\\gince\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\gince\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n",
      "    app.start()\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\gince\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\gince\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\gince\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\gince\\AppData\\Local\\Temp\\ipykernel_17728\\3087116518.py\", line 1, in <cell line: 1>\n",
      "    training_history = trainer.train(\n",
      "  File \"E:\\Github\\NeuroTorch\\src\\neurotorch\\trainers\\trainer.py\", line 233, in train\n",
      "    itr_loss = self._exec_iteration(train_dataloader, val_dataloader)\n",
      "  File \"E:\\Github\\NeuroTorch\\src\\neurotorch\\trainers\\trainer.py\", line 266, in _exec_iteration\n",
      "    train_loss = self._exec_epoch(train_dataloader)\n",
      "  File \"E:\\Github\\NeuroTorch\\src\\neurotorch\\trainers\\trainer.py\", line 299, in _exec_epoch\n",
      "    batch_loss = self._exec_batch(x_batch, y_batch)\n",
      "  File \"E:\\Github\\NeuroTorch\\src\\neurotorch\\trainers\\trainer.py\", line 314, in _exec_batch\n",
      "    regularization_loss = self.regularization()\n",
      "  File \"E:\\Github\\NeuroTorch\\src\\neurotorch\\regularization\\__init__.py\", line 33, in __call__\n",
      "    out = super(BaseRegularization, self).__call__(*args, **kwargs)\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"E:\\Github\\NeuroTorch\\src\\neurotorch\\regularization\\__init__.py\", line 78, in forward\n",
      "    loss = sum([regularization(*args, **kwargs) for regularization in self.regularizations])\n",
      "  File \"E:\\Github\\NeuroTorch\\src\\neurotorch\\regularization\\__init__.py\", line 78, in <listcomp>\n",
      "    loss = sum([regularization(*args, **kwargs) for regularization in self.regularizations])\n",
      "  File \"E:\\Github\\NeuroTorch\\src\\neurotorch\\regularization\\__init__.py\", line 33, in __call__\n",
      "    out = super(BaseRegularization, self).__call__(*args, **kwargs)\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"E:\\Github\\NeuroTorch\\src\\neurotorch\\regularization\\__init__.py\", line 78, in forward\n",
      "    loss = sum([regularization(*args, **kwargs) for regularization in self.regularizations])\n",
      "  File \"E:\\Github\\NeuroTorch\\src\\neurotorch\\regularization\\__init__.py\", line 78, in <listcomp>\n",
      "    loss = sum([regularization(*args, **kwargs) for regularization in self.regularizations])\n",
      "  File \"E:\\Github\\NeuroTorch\\src\\neurotorch\\regularization\\__init__.py\", line 33, in __call__\n",
      "    out = super(BaseRegularization, self).__call__(*args, **kwargs)\n",
      "  File \"E:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"E:\\Github\\NeuroTorch\\src\\neurotorch\\regularization\\__init__.py\", line 109, in forward\n",
      "    loss = loss + torch.sum(torch.abs(param) ** self.p) ** (1.0 / self.p)\n",
      " (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [256, 20]] is at version 11; expected version 10 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m training_history \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mval\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mn_iterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_iterations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mload_checkpoint_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mLoadCheckpointMode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLAST_ITR\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m\t\u001B[49m\u001B[38;5;66;43;03m# force_overwrite=True,\u001B[39;49;00m\n\u001B[0;32m      7\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Github\\NeuroTorch\\src\\neurotorch\\trainers\\trainer.py:233\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, train_dataloader, val_dataloader, n_iterations, load_checkpoint_mode, force_overwrite, p_bar_position, p_bar_leave, **kwargs)\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m p_bar:\n\u001B[0;32m    232\u001B[0m \t\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_training_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_training_state\u001B[38;5;241m.\u001B[39mupdate(iteration\u001B[38;5;241m=\u001B[39mi)\n\u001B[1;32m--> 233\u001B[0m \titr_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_exec_iteration\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    234\u001B[0m \t\u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexec_metrics_on_train\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    235\u001B[0m \t\titr_train_metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exec_metrics(train_dataloader, prefix\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mE:\\Github\\NeuroTorch\\src\\neurotorch\\trainers\\trainer.py:266\u001B[0m, in \u001B[0;36mTrainer._exec_iteration\u001B[1;34m(self, train_dataloader, val_dataloader)\u001B[0m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_training_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_training_state\u001B[38;5;241m.\u001B[39mupdate(batch_is_train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 266\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_exec_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    267\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_training_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_training_state\u001B[38;5;241m.\u001B[39mupdate(train_loss\u001B[38;5;241m=\u001B[39mtrain_loss)\n\u001B[0;32m    268\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mon_train_end(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[1;32mE:\\Github\\NeuroTorch\\src\\neurotorch\\trainers\\trainer.py:299\u001B[0m, in \u001B[0;36mTrainer._exec_epoch\u001B[1;34m(self, dataloader)\u001B[0m\n\u001B[0;32m    297\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (x_batch, y_batch) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader):\n\u001B[0;32m    298\u001B[0m \t\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_training_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_training_state\u001B[38;5;241m.\u001B[39mupdate(batch\u001B[38;5;241m=\u001B[39mi)\n\u001B[1;32m--> 299\u001B[0m \tbatch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_exec_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    300\u001B[0m \tbatch_losses\u001B[38;5;241m.\u001B[39mappend(batch_loss)\n\u001B[0;32m    301\u001B[0m mean_loss \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(batch_losses)\n",
      "File \u001B[1;32mE:\\Github\\NeuroTorch\\src\\neurotorch\\trainers\\trainer.py:326\u001B[0m, in \u001B[0;36mTrainer._exec_batch\u001B[1;34m(self, x_batch, y_batch)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregularization_optimizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    325\u001B[0m \t\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregularization_optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m--> 326\u001B[0m \t\u001B[43mregularization_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    327\u001B[0m \t\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregularization_optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    328\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_training_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_training_state\u001B[38;5;241m.\u001B[39mupdate(batch_loss\u001B[38;5;241m=\u001B[39mbatch_loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[1;32mE:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\torch\\_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[0;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[1;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Github\\NeuroTorch\\applications\\heidelberg\\heidelberg_venv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [256, 20]] is at version 11; expected version 10 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "training_history = trainer.train(\n",
    "\tdataloaders[\"train\"],\n",
    "\tdataloaders[\"val\"],\n",
    "\tn_iterations=n_iterations,\n",
    "\tload_checkpoint_mode=LoadCheckpointMode.LAST_ITR,\n",
    "\t# force_overwrite=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The training is finished! Let's see how our network learned over the iterations.\n",
    "\n",
    "Note: the next graphs are really useful to see if the model overfit or underfit the data over the iterations. It's why you can use the callback `TrainingHistoryVisualizationCallback` to see those graphs in real time."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_history.plot(show=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can load the model at the best or the last iteration for the testing phase."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network.load_checkpoint(checkpoint_manager.checkpoints_meta_path, LoadCheckpointMode.BEST_ITR, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now see how our network perform on the test dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = {\n",
    "\tk: ClassificationMetrics.compute_y_true_y_pred(network, dataloader, verbose=True, desc=f\"{k} predictions\")\n",
    "\tfor k, dataloader in dataloaders.items()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracies = {\n",
    "\tk: ClassificationMetrics.accuracy(network, y_true=y_true, y_pred=y_pred)\n",
    "\tfor k, (y_true, y_pred) in predictions.items()\n",
    "}\n",
    "pprint.pprint(accuracies)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see the results on other popular classification metrics."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precisions = {\n",
    "\tk: ClassificationMetrics.precision(network, y_true=y_true, y_pred=y_pred)\n",
    "\tfor k, (y_true, y_pred) in predictions.items()\n",
    "}\n",
    "recalls = {\n",
    "\tk: ClassificationMetrics.recall(network, y_true=y_true, y_pred=y_pred)\n",
    "\tfor k, (y_true, y_pred) in predictions.items()\n",
    "}\n",
    "f1s = {\n",
    "\tk: ClassificationMetrics.f1(network, y_true=y_true, y_pred=y_pred)\n",
    "\tfor k, (y_true, y_pred) in predictions.items()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = OrderedDict(dict(\n",
    "\tnetwork=network,\n",
    "\taccuracies=accuracies,\n",
    "\tprecisions=precisions,\n",
    "\trecalls=recalls,\n",
    "\tf1s=f1s,\n",
    "))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pprint.pprint(results, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the end of the tutorial!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "NeuroTorch is a library that allows you to easily build neural networks and train them. Moreover, it allows you to do image classification using dynamics from neurosciences."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}